
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/tutorial_mibitof.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/theislab/squidpy_notebooks/master?filepath=docs/source/auto_tutorials/tutorial_mibitof.ipynb
      :alt: Launch binder
      :width: 150 px

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_tutorial_mibitof.py:

Analyze MIBI-TOF image data
===========================

This tutorial shows how to apply Squidpy to MIBI-TOF data.

The data used here comes from a recent paper from :cite:`hartmann2020multiplexed`.
We provide a pre-processed subset of the data, in :class:`anndata.AnnData` format.
For details on how it was pre-processed, please refer to the original paper.

.. seealso::

    See :ref:`sphx_glr_auto_tutorials_tutorial_visium_hne.py` for additional analysis using images
    and :ref:`sphx_glr_auto_tutorials_tutorial_seqfish.py` for analysis using spatial graph functions.

Import packages & data
----------------------
To run the notebook locally, create a conda environment as *conda env create -f environment.yml* using this
`environment.yml <https://github.com/theislab/squidpy_notebooks/blob/master/environment.yml>`_.

.. GENERATED FROM PYTHON SOURCE LINES 22-32

.. code-block:: default


    import scanpy as sc
    import squidpy as sq

    import numpy as np

    import matplotlib.pyplot as plt

    adata = sq.datasets.mibitof()








.. GENERATED FROM PYTHON SOURCE LINES 33-48

The subset of the data we consider here comprises three biopsies colorectal carcinoma biopsies
from different donors, where MIBI-TOF was used to measure single-cell metabolic profiles.
As imaging information, we included three raw image channels:

  - `145_CD45` - a immune cell marker (cyan).
  - `174_CK` - a tumor marker (magenta).
  - `113_vimentin` - a mesenchymal cell marker (yellow).

and a cell segmentation mask provided by the authors of the original paper.

The `adata` object contains three different libraries, one for each biopsy.
The images are contained in ``adata.uns['spatial'][<library_id>]['images']``.
Let us visualize the cluster annotations for each library using :func:`scanpy.pl.spatial`.
For this, we need to subset `adata` to the desired `library_id`, using the mapping from `obs`
to `library_id` provided by ``adata.obs['library_id']``.

.. GENERATED FROM PYTHON SOURCE LINES 48-54

.. code-block:: default


    for library_id in adata.uns["spatial"].keys():
        sc.pl.spatial(
            adata[adata.obs["library_id"] == library_id], color="Cluster", library_id=library_id, title=library_id
        )




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_mibitof_001.png
         :alt: point16
         :srcset: /auto_tutorials/images/sphx_glr_tutorial_mibitof_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_mibitof_002.png
         :alt: point23
         :srcset: /auto_tutorials/images/sphx_glr_tutorial_mibitof_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_mibitof_003.png
         :alt: point8
         :srcset: /auto_tutorials/images/sphx_glr_tutorial_mibitof_003.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 55-60

Let us create an ImageContainer from the images contained in `adata`.
As all three biopsies are already joined in `adata`, let us also create one ImageContainer for
all three biopsies using a z-stack.
For more information on how to use `ImageContainer` with z-stacks, also have a look at
:ref:`sphx_glr_auto_tutorials_tutorial_image_container_zstacks.py`.

.. GENERATED FROM PYTHON SOURCE LINES 60-68

.. code-block:: default

    imgs = []
    for library_id in adata.uns["spatial"].keys():
        img = sq.im.ImageContainer(adata.uns["spatial"][library_id]["images"]["hires"], library_id=library_id)
        img.add_img(adata.uns["spatial"][library_id]["images"]["segmentation"], library_id=library_id, layer="segmentation")
        img["segmentation"].attrs["segmentation"] = True
        imgs.append(img)
    img = sq.im.ImageContainer.concat(imgs)








.. GENERATED FROM PYTHON SOURCE LINES 69-72

Note that we also added the segmentation as an additional layer to `img`, and set the
`segmentation` attribute in the ImageContainer.
This allows visualization of the segmentation layer as a `labels` layer in Napari.

.. GENERATED FROM PYTHON SOURCE LINES 72-74

.. code-block:: default

    img






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    ImageContainer object with 2 layers:<p style='text-indent: 25px; margin-top: 0px; margin-bottom: 0px;'><strong>image</strong>: <em>y</em> (1024), <em>x</em> (1024), <em>z</em> (3), <em>channels</em> (3)</p><p style='text-indent: 25px; margin-top: 0px; margin-bottom: 0px;'><strong>segmentation</strong>: <em>y</em> (1024), <em>x</em> (1024), <em>z</em> (3), <em>channels_0</em> (1)</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 75-81

If you have Napari installed, you can have a look at the data using the interactive viewer:
Note that you can load the segmentation layer as an overlay over the image.

.. code-block:: python

    img.interactive(adata, library_key='library_id')

.. GENERATED FROM PYTHON SOURCE LINES 83-84

Let us also statically visualize the data in `img`, using :func:`squidpy.im.ImageCntainer.show`:

.. GENERATED FROM PYTHON SOURCE LINES 84-87

.. code-block:: default

    img.show("image")
    img.show("image", segmentation_layer="segmentation")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_mibitof_004.png
         :alt: image, library_id:point16, image, library_id:point23, image, library_id:point8
         :srcset: /auto_tutorials/images/sphx_glr_tutorial_mibitof_004.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_mibitof_005.png
         :alt: image, library_id:point16, image, library_id:point23, image, library_id:point8
         :srcset: /auto_tutorials/images/sphx_glr_tutorial_mibitof_005.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 88-95

In the following we show how to use Squidpy to extract cellular mean intensity information using raw images
and a provided segmentation mask.
In the present case, `adata` of course already contains the post-processed cellular mean intensity
for the raw image channels.
The aim of this tutorial, however, is to showcase how the extraction of such features is possible using Squidpy.
As Squidpy is backed by :mod:`dask` and supports chunked image processing,
also large images can be processed in this way.

.. GENERATED FROM PYTHON SOURCE LINES 97-104

Convert image to CMYK
---------------------
As already mentioned, the images contain information from three raw channels, `145_CD45`,
`174_CK`, and `113_vimentin`.
As the channel information is encoded in CMYK space, we first need to convert the RGB images to CMYK.

For this, we can use :meth:`squidpy.im.ImageContainer.apply`.

.. GENERATED FROM PYTHON SOURCE LINES 104-121

.. code-block:: default



    def rgb2cmyk(arr):
        """Convert arr from RGB to CMYK color space."""
        R = arr[..., 0] / 255
        G = arr[..., 1] / 255
        B = arr[..., 2] / 255
        K = 1 - (np.max(arr, axis=-1) / 255)
        C = (1 - R - K) / (1 - K + np.finfo(float).eps)  # avoid division by 0
        M = (1 - G - K) / (1 - K + np.finfo(float).eps)
        Y = (1 - B - K) / (1 - K + np.finfo(float).eps)
        return np.stack([C, M, Y, K], axis=3)


    img.apply(rgb2cmyk, layer="image", new_layer="image_cmyk", copy=False)
    img.show("image_cmyk", channelwise=True)




.. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_mibitof_006.png
   :alt: image_cmyk:0, library_id:point16, image_cmyk:1, library_id:point16, image_cmyk:2, library_id:point16, image_cmyk:3, library_id:point16, image_cmyk:0, library_id:point23, image_cmyk:1, library_id:point23, image_cmyk:2, library_id:point23, image_cmyk:3, library_id:point23, image_cmyk:0, library_id:point8, image_cmyk:1, library_id:point8, image_cmyk:2, library_id:point8, image_cmyk:3, library_id:point8
   :srcset: /auto_tutorials/images/sphx_glr_tutorial_mibitof_006.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 122-137

Extract per-cell mean intensity
-------------------------------
Now that we have disentangled the individual channels, let use use the provided segmentation mask
to extract per-cell mean intensities.

By default, the `segmentation` feature extractor extracts information using all segments (cells)
in the current crop.
As we would like to only get information of the segment (cell) in the center of the current crop,
let us use a `custom` feature extractor.

Fist, define a custom feature extraction function. This function needs to get the segmentation mask
and the original image as input.
We will achieve this by passing an ``additional_layers`` argument to the `custom` feature extractor.
This special argument will pass the values of every layer in `additional_layers`
to the custom feature extraction function.

.. GENERATED FROM PYTHON SOURCE LINES 137-164

.. code-block:: default



    def segmentation_image_intensity(arr, image_cmyk):
        """
        Calculate per-channel mean intensity of the center segment.

        arr: the segmentation
        image_cmyk: the raw image values
        """
        import skimage.measure

        # the center of the segmentation mask contains the current label
        # use that to calculate the mask
        s = arr.shape[0]
        mask = (arr == arr[s // 2, s // 2, 0, 0]).astype(int)
        # use skimage.measure.regionprops to get the intensity per channel
        features = []
        for c in range(image_cmyk.shape[-1]):
            feature = skimage.measure.regionprops_table(
                np.squeeze(mask),  # skimage needs 3d or 2d images, so squeeze excess dims
                intensity_image=np.squeeze(image_cmyk[:, :, :, c]),
                properties=["mean_intensity"],
            )["mean_intensity"][0]
            features.append(feature)
        return features









.. GENERATED FROM PYTHON SOURCE LINES 165-169

Now, use :func:`squidpy.im.calculate_image_features` with the `custom` feature extractor,
specifying the function (``func``) to use, and the additional layers (``additional_layers``)
to pass to the function.
We will use ``spot_scale = 10`` to ensure that we also cover big segments fully by one crop.

.. GENERATED FROM PYTHON SOURCE LINES 169-179

.. code-block:: default

    sq.im.calculate_image_features(
        adata,
        img,
        library_id="library_id",
        features="custom",
        spot_scale=10,
        layer="segmentation",
        features_kwargs={"custom": {"func": segmentation_image_intensity, "additional_layers": ["image_cmyk"]}},
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|          | 0/3309 [00:00<?, ?/s]      0%|          | 3/3309 [00:00<01:51, 29.68/s]      1%|          | 19/3309 [00:00<00:32, 102.20/s]      1%|1         | 36/3309 [00:00<00:25, 129.33/s]      2%|1         | 52/3309 [00:00<00:23, 138.68/s]      2%|2         | 68/3309 [00:00<00:22, 144.93/s]      3%|2         | 84/3309 [00:00<00:21, 148.88/s]      3%|3         | 101/3309 [00:00<00:20, 153.19/s]      4%|3         | 119/3309 [00:00<00:20, 158.79/s]      4%|4         | 136/3309 [00:00<00:19, 161.82/s]      5%|4         | 154/3309 [00:01<00:19, 165.13/s]      5%|5         | 171/3309 [00:01<00:18, 165.93/s]      6%|5         | 188/3309 [00:01<00:18, 167.01/s]      6%|6         | 205/3309 [00:01<00:18, 165.55/s]      7%|6         | 223/3309 [00:01<00:18, 168.90/s]      7%|7         | 240/3309 [00:01<00:18, 168.93/s]      8%|7         | 257/3309 [00:01<00:18, 168.33/s]      8%|8         | 274/3309 [00:01<00:18, 167.95/s]      9%|8         | 291/3309 [00:01<00:18, 167.55/s]      9%|9         | 309/3309 [00:01<00:17, 168.79/s]     10%|9         | 326/3309 [00:02<00:17, 169.13/s]     10%|#         | 343/3309 [00:02<00:17, 169.18/s]     11%|#         | 360/3309 [00:02<00:17, 168.20/s]     11%|#1        | 377/3309 [00:02<00:17, 168.29/s]     12%|#1        | 395/3309 [00:02<00:17, 169.23/s]     12%|#2        | 412/3309 [00:02<00:17, 169.35/s]     13%|#2        | 429/3309 [00:02<00:16, 169.47/s]     13%|#3        | 446/3309 [00:02<00:16, 168.77/s]     14%|#4        | 464/3309 [00:02<00:16, 168.99/s]     15%|#4        | 482/3309 [00:02<00:16, 169.15/s]     15%|#5        | 499/3309 [00:03<00:16, 169.22/s]     16%|#5        | 517/3309 [00:03<00:16, 169.46/s]     16%|#6        | 534/3309 [00:03<00:16, 167.72/s]     17%|#6        | 552/3309 [00:03<00:16, 171.06/s]     17%|#7        | 570/3309 [00:03<00:16, 170.48/s]     18%|#7        | 588/3309 [00:03<00:15, 170.73/s]     18%|#8        | 606/3309 [00:03<00:15, 170.98/s]     19%|#8        | 624/3309 [00:03<00:15, 169.36/s]     19%|#9        | 642/3309 [00:03<00:15, 169.63/s]     20%|#9        | 659/3309 [00:04<00:15, 169.51/s]     20%|##        | 676/3309 [00:04<00:15, 169.20/s]     21%|##        | 694/3309 [00:04<00:15, 169.34/s]     21%|##1       | 711/3309 [00:04<00:15, 169.28/s]     22%|##2       | 728/3309 [00:04<00:15, 168.97/s]     23%|##2       | 746/3309 [00:04<00:15, 169.34/s]     23%|##3       | 763/3309 [00:04<00:15, 169.48/s]     24%|##3       | 780/3309 [00:04<00:14, 168.98/s]     24%|##4       | 797/3309 [00:04<00:14, 168.75/s]     25%|##4       | 815/3309 [00:04<00:14, 169.47/s]     25%|##5       | 832/3309 [00:05<00:14, 169.47/s]     26%|##5       | 850/3309 [00:05<00:14, 169.77/s]     26%|##6       | 867/3309 [00:05<00:14, 169.67/s]     27%|##6       | 884/3309 [00:05<00:14, 169.03/s]     27%|##7       | 901/3309 [00:05<00:14, 168.65/s]     28%|##7       | 919/3309 [00:05<00:14, 168.99/s]     28%|##8       | 936/3309 [00:05<00:14, 169.21/s]     29%|##8       | 954/3309 [00:05<00:13, 168.86/s]     29%|##9       | 972/3309 [00:05<00:13, 169.73/s]     30%|##9       | 989/3309 [00:05<00:13, 169.79/s]     30%|###       | 1006/3309 [00:06<00:13, 169.03/s]     31%|###       | 1023/3309 [00:06<00:13, 168.39/s]     31%|###1      | 1040/3309 [00:06<00:13, 168.60/s]     32%|###1      | 1058/3309 [00:06<00:13, 168.97/s]     32%|###2      | 1075/3309 [00:06<00:13, 166.97/s]     33%|###3      | 1093/3309 [00:06<00:13, 167.36/s]     34%|###3      | 1111/3309 [00:06<00:12, 169.98/s]     34%|###4      | 1129/3309 [00:06<00:12, 169.71/s]     35%|###4      | 1146/3309 [00:06<00:12, 169.35/s]     35%|###5      | 1163/3309 [00:07<00:12, 168.16/s]     36%|###5      | 1180/3309 [00:07<00:13, 162.96/s]     36%|###6      | 1197/3309 [00:07<00:12, 164.14/s]     37%|###6      | 1214/3309 [00:07<00:12, 163.59/s]     37%|###7      | 1231/3309 [00:07<00:12, 163.53/s]     38%|###7      | 1248/3309 [00:07<00:12, 162.84/s]     38%|###8      | 1265/3309 [00:07<00:12, 162.55/s]     39%|###8      | 1282/3309 [00:07<00:12, 161.59/s]     39%|###9      | 1299/3309 [00:07<00:12, 161.20/s]     40%|###9      | 1316/3309 [00:07<00:12, 161.83/s]     40%|####      | 1333/3309 [00:08<00:12, 163.60/s]     41%|####      | 1350/3309 [00:08<00:11, 164.11/s]     41%|####1     | 1367/3309 [00:08<00:11, 163.80/s]     42%|####1     | 1385/3309 [00:08<00:11, 165.65/s]     42%|####2     | 1402/3309 [00:08<00:11, 166.85/s]     43%|####2     | 1419/3309 [00:08<00:11, 166.68/s]     43%|####3     | 1436/3309 [00:08<00:11, 166.22/s]     44%|####3     | 1453/3309 [00:08<00:11, 166.78/s]     44%|####4     | 1470/3309 [00:08<00:11, 166.68/s]     45%|####4     | 1487/3309 [00:08<00:10, 165.96/s]     45%|####5     | 1504/3309 [00:09<00:10, 166.68/s]     46%|####5     | 1521/3309 [00:09<00:10, 166.82/s]     46%|####6     | 1538/3309 [00:09<00:10, 166.63/s]     47%|####6     | 1555/3309 [00:09<00:10, 166.24/s]     48%|####7     | 1573/3309 [00:09<00:10, 167.52/s]     48%|####8     | 1590/3309 [00:09<00:10, 167.42/s]     49%|####8     | 1607/3309 [00:09<00:10, 167.26/s]     49%|####9     | 1624/3309 [00:09<00:10, 167.40/s]     50%|####9     | 1641/3309 [00:09<00:09, 167.08/s]     50%|#####     | 1658/3309 [00:10<00:09, 167.00/s]     51%|#####     | 1675/3309 [00:10<00:09, 167.03/s]     51%|#####1    | 1692/3309 [00:10<00:09, 166.69/s]     52%|#####1    | 1709/3309 [00:10<00:09, 166.55/s]     52%|#####2    | 1726/3309 [00:10<00:09, 166.51/s]     53%|#####2    | 1743/3309 [00:10<00:09, 167.10/s]     53%|#####3    | 1760/3309 [00:10<00:09, 166.92/s]     54%|#####3    | 1777/3309 [00:10<00:09, 166.98/s]     54%|#####4    | 1794/3309 [00:10<00:09, 167.43/s]     55%|#####4    | 1811/3309 [00:10<00:08, 167.31/s]     55%|#####5    | 1829/3309 [00:11<00:08, 168.26/s]     56%|#####5    | 1846/3309 [00:11<00:08, 167.99/s]     56%|#####6    | 1863/3309 [00:11<00:08, 168.14/s]     57%|#####6    | 1880/3309 [00:11<00:08, 168.64/s]     57%|#####7    | 1897/3309 [00:11<00:08, 168.14/s]     58%|#####7    | 1915/3309 [00:11<00:08, 168.89/s]     58%|#####8    | 1932/3309 [00:11<00:08, 167.98/s]     59%|#####8    | 1949/3309 [00:11<00:08, 168.02/s]     59%|#####9    | 1966/3309 [00:11<00:07, 168.21/s]     60%|#####9    | 1983/3309 [00:11<00:07, 168.12/s]     60%|######    | 2000/3309 [00:12<00:07, 167.43/s]     61%|######    | 2017/3309 [00:12<00:07, 167.86/s]     61%|######1   | 2034/3309 [00:12<00:07, 166.77/s]     62%|######1   | 2051/3309 [00:12<00:07, 165.02/s]     63%|######2   | 2069/3309 [00:12<00:07, 168.06/s]     63%|######3   | 2087/3309 [00:12<00:07, 168.41/s]     64%|######3   | 2104/3309 [00:12<00:07, 168.52/s]     64%|######4   | 2121/3309 [00:12<00:07, 168.47/s]     65%|######4   | 2138/3309 [00:12<00:06, 168.38/s]     65%|######5   | 2155/3309 [00:12<00:06, 168.35/s]     66%|######5   | 2172/3309 [00:13<00:06, 168.09/s]     66%|######6   | 2189/3309 [00:13<00:06, 168.55/s]     67%|######6   | 2206/3309 [00:13<00:06, 167.85/s]     67%|######7   | 2223/3309 [00:13<00:06, 167.51/s]     68%|######7   | 2240/3309 [00:13<00:06, 164.78/s]     68%|######8   | 2257/3309 [00:13<00:06, 164.15/s]     69%|######8   | 2274/3309 [00:13<00:06, 162.86/s]     69%|######9   | 2291/3309 [00:13<00:06, 162.89/s]     70%|######9   | 2308/3309 [00:13<00:06, 163.15/s]     70%|#######   | 2325/3309 [00:14<00:06, 162.47/s]     71%|#######   | 2342/3309 [00:14<00:05, 161.67/s]     71%|#######1  | 2359/3309 [00:14<00:05, 160.39/s]     72%|#######1  | 2376/3309 [00:14<00:05, 160.27/s]     72%|#######2  | 2393/3309 [00:14<00:05, 162.83/s]     73%|#######2  | 2410/3309 [00:14<00:05, 162.74/s]     73%|#######3  | 2428/3309 [00:14<00:05, 164.95/s]     74%|#######3  | 2445/3309 [00:14<00:05, 166.10/s]     74%|#######4  | 2463/3309 [00:14<00:05, 166.96/s]     75%|#######4  | 2480/3309 [00:14<00:04, 167.68/s]     75%|#######5  | 2497/3309 [00:15<00:04, 167.53/s]     76%|#######5  | 2514/3309 [00:15<00:04, 168.00/s]     76%|#######6  | 2531/3309 [00:15<00:04, 168.36/s]     77%|#######7  | 2548/3309 [00:15<00:04, 167.70/s]     78%|#######7  | 2566/3309 [00:15<00:04, 168.84/s]     78%|#######8  | 2583/3309 [00:15<00:04, 168.77/s]     79%|#######8  | 2600/3309 [00:15<00:04, 168.09/s]     79%|#######9  | 2617/3309 [00:15<00:04, 168.56/s]     80%|#######9  | 2634/3309 [00:15<00:04, 168.12/s]     80%|########  | 2651/3309 [00:15<00:03, 168.27/s]     81%|########  | 2668/3309 [00:16<00:03, 168.46/s]     81%|########1 | 2685/3309 [00:16<00:03, 168.41/s]     82%|########1 | 2702/3309 [00:16<00:03, 167.59/s]     82%|########2 | 2719/3309 [00:16<00:03, 167.97/s]     83%|########2 | 2736/3309 [00:16<00:03, 166.15/s]     83%|########3 | 2754/3309 [00:16<00:03, 168.94/s]     84%|########3 | 2771/3309 [00:16<00:03, 168.76/s]     84%|########4 | 2788/3309 [00:16<00:03, 168.10/s]     85%|########4 | 2805/3309 [00:16<00:03, 167.76/s]     85%|########5 | 2822/3309 [00:16<00:02, 167.98/s]     86%|########5 | 2839/3309 [00:17<00:02, 168.48/s]     86%|########6 | 2856/3309 [00:17<00:02, 168.53/s]     87%|########6 | 2873/3309 [00:17<00:02, 168.37/s]     87%|########7 | 2890/3309 [00:17<00:02, 167.83/s]     88%|########7 | 2907/3309 [00:17<00:02, 167.96/s]     88%|########8 | 2924/3309 [00:17<00:02, 168.19/s]     89%|########8 | 2941/3309 [00:17<00:02, 167.69/s]     89%|########9 | 2958/3309 [00:17<00:02, 167.75/s]     90%|########9 | 2975/3309 [00:17<00:01, 167.63/s]     90%|######### | 2993/3309 [00:17<00:01, 168.16/s]     91%|######### | 3011/3309 [00:18<00:01, 168.64/s]     92%|#########1| 3028/3309 [00:18<00:01, 167.83/s]     92%|#########2| 3045/3309 [00:18<00:01, 167.57/s]     93%|#########2| 3063/3309 [00:18<00:01, 168.23/s]     93%|#########3| 3080/3309 [00:18<00:01, 167.34/s]     94%|#########3| 3097/3309 [00:18<00:01, 168.03/s]     94%|#########4| 3114/3309 [00:18<00:01, 166.91/s]     95%|#########4| 3131/3309 [00:18<00:01, 167.38/s]     95%|#########5| 3148/3309 [00:18<00:00, 166.76/s]     96%|#########5| 3165/3309 [00:19<00:00, 167.37/s]     96%|#########6| 3182/3309 [00:19<00:00, 167.91/s]     97%|#########6| 3199/3309 [00:19<00:00, 167.22/s]     97%|#########7| 3216/3309 [00:19<00:00, 167.08/s]     98%|#########7| 3234/3309 [00:19<00:00, 168.12/s]     98%|#########8| 3251/3309 [00:19<00:00, 168.30/s]     99%|#########8| 3268/3309 [00:19<00:00, 165.40/s]     99%|#########9| 3285/3309 [00:19<00:00, 164.41/s]    100%|#########9| 3302/3309 [00:19<00:00, 164.14/s]    100%|##########| 3309/3309 [00:19<00:00, 166.32/s]




.. GENERATED FROM PYTHON SOURCE LINES 180-182

The resulting features are stored in ``adata.obs['img_features']``,
with channel 0 representing `145_CD45`, channel 1 `174_CK`, and channel 2 `113_vimentin`.

.. GENERATED FROM PYTHON SOURCE LINES 182-184

.. code-block:: default

    adata.obsm["img_features"]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>segmentation_image_intensity_0</th>
          <th>segmentation_image_intensity_1</th>
          <th>segmentation_image_intensity_2</th>
          <th>segmentation_image_intensity_3</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>3034-0</th>
          <td>0.000000</td>
          <td>0.995041</td>
          <td>0.010664</td>
          <td>0.492503</td>
        </tr>
        <tr>
          <th>3035-0</th>
          <td>0.000049</td>
          <td>0.884839</td>
          <td>0.042991</td>
          <td>0.713101</td>
        </tr>
        <tr>
          <th>3036-0</th>
          <td>0.680350</td>
          <td>0.000235</td>
          <td>0.222640</td>
          <td>0.948284</td>
        </tr>
        <tr>
          <th>3037-0</th>
          <td>0.813055</td>
          <td>0.000000</td>
          <td>0.173941</td>
          <td>0.790169</td>
        </tr>
        <tr>
          <th>3038-0</th>
          <td>0.420203</td>
          <td>0.015063</td>
          <td>0.486171</td>
          <td>0.709584</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>47342-2</th>
          <td>0.000000</td>
          <td>0.000000</td>
          <td>0.696113</td>
          <td>0.855720</td>
        </tr>
        <tr>
          <th>47343-2</th>
          <td>0.441017</td>
          <td>0.000000</td>
          <td>0.587986</td>
          <td>0.941870</td>
        </tr>
        <tr>
          <th>47344-2</th>
          <td>0.639157</td>
          <td>0.000000</td>
          <td>0.344870</td>
          <td>0.858989</td>
        </tr>
        <tr>
          <th>47345-2</th>
          <td>0.196760</td>
          <td>0.000000</td>
          <td>0.612479</td>
          <td>0.855991</td>
        </tr>
        <tr>
          <th>47346-2</th>
          <td>0.000000</td>
          <td>0.000000</td>
          <td>0.774775</td>
          <td>0.981311</td>
        </tr>
      </tbody>
    </table>
    <p>3309 rows × 4 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 185-188

As described in :cite:`hartmann2020multiplexed`, let us transformed using an
inverse hyperbolic sine (`arcsinh`) co-factor of 0.05, to allow us to compare
the computed mean intensities with the values contained in `adata`.

.. GENERATED FROM PYTHON SOURCE LINES 188-190

.. code-block:: default

    adata.obsm["img_features_transformed"] = np.arcsinh(adata.obsm["img_features"] / 0.05)








.. GENERATED FROM PYTHON SOURCE LINES 191-192

Now, let's visualize the result:

.. GENERATED FROM PYTHON SOURCE LINES 192-204

.. code-block:: default

    channels = ["CD45", "CK", "vimentin"]

    fig, axes = plt.subplots(1, 3, figsize=(15, 3))
    for i, ax in enumerate(axes):
        X = np.array(adata[:, channels[i]].X.todense())[:, 0]
        Y = adata.obsm["img_features_transformed"][f"segmentation_image_intensity_{i}"]
        ax.scatter(X, Y)
        ax.set_xlabel("true value in adata.X")
        ax.set_ylabel("computed mean intensity")
        corr = np.corrcoef(X, Y)[1, 0]
        ax.set_title(f"{channels[i]}, corr: {corr:.2f}")




.. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_mibitof_007.png
   :alt: CD45, corr: 0.84, CK, corr: 0.85, vimentin, corr: 0.70
   :srcset: /auto_tutorials/images/sphx_glr_tutorial_mibitof_007.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 205-215

We get high correlations between the original values and our computation using Squidpy.
The remaining differences are probably due to more pre-processing applied by
the authors of :cite:`hartmann2020multiplexed`.

In this tutorial we have shown how to pre-process imaging data to extract per-cell
counts / mean intensities using Squidpy.
Of course it is also possible to apply spatial statistics functions provided by the
:mod:`squidpy.gr` module to MIBI-TOF data.
For examples of this, please see our other Analysis tutorials, e.g.
:ref:`sphx_glr_auto_tutorials_tutorial_seqfish.py`.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  50.704 seconds)

**Estimated memory usage:**  171 MB


.. _sphx_glr_download_auto_tutorials_tutorial_mibitof.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: tutorial_mibitof.py <tutorial_mibitof.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: tutorial_mibitof.ipynb <tutorial_mibitof.ipynb>`
